{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e60d0003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01ef8cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dyuti\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data has been loaded from 'bcci_data_preprocessed.pkl'\n"
     ]
    }
   ],
   "source": [
    "with open('bcci_data_preprocessed.pkl','rb') as f:\n",
    "    dataset=pickle.load(f)\n",
    "\n",
    "print(\"Preprocessed data has been loaded from 'bcci_data_preprocessed.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16e2c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_window_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc33f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from braindecode.models import Deep4Net\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "cuda = torch.cuda.is_available()  # check if GPU is available, if True chooses to use it\n",
    "device = 'cuda' if cuda else 'cpu'\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "# Set random seed to be able to roughly reproduce results\n",
    "# Note that with cudnn benchmark set to True, GPU indeterminism\n",
    "# may still make results substantially different between runs.\n",
    "# To obtain more consistent results at the cost of increased computation time,\n",
    "# you can set `cudnn_benchmark=False` in `set_random_seeds`\n",
    "# or remove `torch.backends.cudnn.benchmark = True`\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "\n",
    "n_classes = 4\n",
    "classes = list(range(n_classes))\n",
    "# Extract number of chans from dataset\n",
    "n_chans = dataset[0][0].shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d1d9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================\n",
      "Layer (type (var_name):depth-idx)        Input Shape               Output Shape              Param #                   Kernel Shape\n",
      "============================================================================================================================================\n",
      "Deep4Net (Deep4Net)                      [1, 23, 1000]             [1, 4]                    --                        --\n",
      "├─Ensure4d (ensuredims): 1-1             [1, 23, 1000]             [1, 23, 1000, 1]          --                        --\n",
      "├─Rearrange (dimshuffle): 1-2            [1, 23, 1000, 1]          [1, 1, 1000, 23]          --                        --\n",
      "├─CombinedConv (conv_time_spat): 1-3     [1, 1, 1000, 23]          [1, 25, 991, 1]           14,650                    --\n",
      "├─BatchNorm2d (bnorm): 1-4               [1, 25, 991, 1]           [1, 25, 991, 1]           50                        --\n",
      "├─Expression (conv_nonlin): 1-5          [1, 25, 991, 1]           [1, 25, 991, 1]           --                        --\n",
      "├─MaxPool2d (pool): 1-6                  [1, 25, 991, 1]           [1, 25, 330, 1]           --                        [3, 1]\n",
      "├─Expression (pool_nonlin): 1-7          [1, 25, 330, 1]           [1, 25, 330, 1]           --                        --\n",
      "├─Dropout (drop_2): 1-8                  [1, 25, 330, 1]           [1, 25, 330, 1]           --                        --\n",
      "├─Conv2d (conv_2): 1-9                   [1, 25, 330, 1]           [1, 50, 321, 1]           12,500                    [10, 1]\n",
      "├─BatchNorm2d (bnorm_2): 1-10            [1, 50, 321, 1]           [1, 50, 321, 1]           100                       --\n",
      "├─Expression (nonlin_2): 1-11            [1, 50, 321, 1]           [1, 50, 321, 1]           --                        --\n",
      "├─MaxPool2d (pool_2): 1-12               [1, 50, 321, 1]           [1, 50, 107, 1]           --                        [3, 1]\n",
      "├─Expression (pool_nonlin_2): 1-13       [1, 50, 107, 1]           [1, 50, 107, 1]           --                        --\n",
      "├─Dropout (drop_3): 1-14                 [1, 50, 107, 1]           [1, 50, 107, 1]           --                        --\n",
      "├─Conv2d (conv_3): 1-15                  [1, 50, 107, 1]           [1, 100, 98, 1]           50,000                    [10, 1]\n",
      "├─BatchNorm2d (bnorm_3): 1-16            [1, 100, 98, 1]           [1, 100, 98, 1]           200                       --\n",
      "├─Expression (nonlin_3): 1-17            [1, 100, 98, 1]           [1, 100, 98, 1]           --                        --\n",
      "├─MaxPool2d (pool_3): 1-18               [1, 100, 98, 1]           [1, 100, 32, 1]           --                        [3, 1]\n",
      "├─Expression (pool_nonlin_3): 1-19       [1, 100, 32, 1]           [1, 100, 32, 1]           --                        --\n",
      "├─Dropout (drop_4): 1-20                 [1, 100, 32, 1]           [1, 100, 32, 1]           --                        --\n",
      "├─Conv2d (conv_4): 1-21                  [1, 100, 32, 1]           [1, 200, 23, 1]           200,000                   [10, 1]\n",
      "├─BatchNorm2d (bnorm_4): 1-22            [1, 200, 23, 1]           [1, 200, 23, 1]           400                       --\n",
      "├─Expression (nonlin_4): 1-23            [1, 200, 23, 1]           [1, 200, 23, 1]           --                        --\n",
      "├─MaxPool2d (pool_4): 1-24               [1, 200, 23, 1]           [1, 200, 7, 1]            --                        [3, 1]\n",
      "├─Expression (pool_nonlin_4): 1-25       [1, 200, 7, 1]            [1, 200, 7, 1]            --                        --\n",
      "├─Sequential (final_layer): 1-26         [1, 200, 7, 1]            [1, 4]                    --                        --\n",
      "│    └─Conv2d (conv_classifier): 2-1     [1, 200, 7, 1]            [1, 4, 1, 1]              5,604                     [7, 1]\n",
      "│    └─LogSoftmax (logsoftmax): 2-2      [1, 4, 1, 1]              [1, 4, 1, 1]              --                        --\n",
      "│    └─Expression (squeeze): 2-3         [1, 4, 1, 1]              [1, 4]                    --                        --\n",
      "============================================================================================================================================\n",
      "Total params: 283,504\n",
      "Trainable params: 283,504\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.MEGABYTES): 13.52\n",
      "============================================================================================================================================\n",
      "Input size (MB): 0.09\n",
      "Forward/backward pass size (MB): 0.69\n",
      "Params size (MB): 1.08\n",
      "Estimated Total Size (MB): 1.85\n",
      "============================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = Deep4Net(\n",
    "    n_chans,\n",
    "    n_classes,\n",
    "    input_window_samples=input_window_samples,\n",
    "    final_conv_length='auto',\n",
    "    batch_norm_alpha=0\n",
    ")\n",
    "\n",
    "# Display torchinfo table describing the model\n",
    "print(model)\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    _ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "254c2111",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_dense_prediction_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47288dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_preds_per_input = model.get_output_shape()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d065058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import create_windows_from_events\n",
    "\n",
    "trial_start_offset_seconds = -0.5\n",
    "# Extract sampling frequency, check that they are same in all datasets\n",
    "sfreq = dataset.datasets[0].raw.info['sfreq']\n",
    "assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
    "\n",
    "# Calculate the trial start offset in samples.\n",
    "trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "# Create windows using braindecode function for this. It needs parameters to define how\n",
    "# trials should be used.\n",
    "windows_dataset = create_windows_from_events(\n",
    "    dataset,\n",
    "    trial_start_offset_samples=trial_start_offset_samples,\n",
    "    trial_stop_offset_samples=0,\n",
    "    window_size_samples=input_window_samples,\n",
    "    window_stride_samples=n_preds_per_input,\n",
    "    drop_last_window=False,\n",
    "    preload=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b038a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted = windows_dataset.split('session')\n",
    "train_set = splitted['0train']  # Session train\n",
    "valid_set = splitted['1test'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3863b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.training import CroppedLoss\n",
    "\n",
    "# For deep4 they should be:\n",
    "lr = 1 * 0.01\n",
    "weight_decay = 0.5 * 0.001\n",
    "\n",
    "batch_size=64\n",
    "n_epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0435c724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_loss    valid_accuracy    valid_loss      lr       dur\n",
      "-------  ----------------  ------------  ----------------  ------------  ------  --------\n",
      "      1            \u001b[36m0.2909\u001b[0m        \u001b[32m1.8675\u001b[0m            \u001b[35m0.2990\u001b[0m      \u001b[31m270.3975\u001b[0m  0.0100  973.5391\n",
      "      2            0.2500        \u001b[32m1.4941\u001b[0m            0.2500     1353.4364  0.0100  641.8380\n",
      "      3            0.2535        \u001b[32m1.3362\u001b[0m            0.2519      554.2991  0.0099  630.1099\n",
      "      4            0.2581        \u001b[32m1.2333\u001b[0m            0.2531      621.9261  0.0097  2016.2003\n",
      "      5            0.2654        \u001b[32m1.1677\u001b[0m            0.2600      521.8598  0.0095  2009.0304\n",
      "      6            0.2500        \u001b[32m1.1106\u001b[0m            0.2496      725.6219  0.0093  1588.7855\n",
      "      7            0.2500        \u001b[32m1.0926\u001b[0m            0.2515     1903.9499  0.0090  591.6234\n",
      "      8            0.2500        \u001b[32m1.0529\u001b[0m            0.2504     3242.8428  0.0086  590.8598\n",
      "      9            0.2785        \u001b[32m1.0212\u001b[0m            0.2793     1450.5325  0.0082  580.1401\n",
      "     10            0.2851        \u001b[32m0.9874\u001b[0m            0.2867     1036.9663  0.0078  577.8539\n",
      "     11            \u001b[36m0.3854\u001b[0m        \u001b[32m0.9525\u001b[0m            \u001b[35m0.3611\u001b[0m      644.5881  0.0073  581.4883\n",
      "     12            0.3549        \u001b[32m0.9295\u001b[0m            0.3387      531.0920  0.0069  580.6236\n",
      "     13            0.3079        \u001b[32m0.9071\u001b[0m            0.3125      674.5825  0.0063  587.4321\n",
      "     14            0.2554        \u001b[32m0.8903\u001b[0m            0.2539     1348.7227  0.0058  592.2737\n",
      "     15            0.2720        \u001b[32m0.8605\u001b[0m            0.2647      972.5458  0.0053  573.7547\n",
      "     16            0.2901        \u001b[32m0.8308\u001b[0m            0.2743      534.6260  0.0047  573.4434\n",
      "     17            0.2674        \u001b[32m0.8231\u001b[0m            0.2674      853.2171  0.0042  574.1025\n",
      "     18            0.3758        \u001b[32m0.7889\u001b[0m            \u001b[35m0.3627\u001b[0m      328.5337  0.0037  583.4590\n",
      "     19            \u001b[36m0.3889\u001b[0m        \u001b[32m0.7714\u001b[0m            \u001b[35m0.3765\u001b[0m      481.4210  0.0031  574.6729\n",
      "     20            \u001b[36m0.3970\u001b[0m        \u001b[32m0.7514\u001b[0m            \u001b[35m0.3823\u001b[0m      356.4997  0.0027  580.8032\n",
      "     21            0.2670        \u001b[32m0.7323\u001b[0m            0.2670      792.5120  0.0022  574.1726\n",
      "     22            0.3515        \u001b[32m0.7166\u001b[0m            0.3187      279.0378  0.0018  576.8483\n",
      "     23            0.2681        \u001b[32m0.7017\u001b[0m            0.2662      518.0526  0.0014  577.6591\n",
      "     24            0.2739        \u001b[32m0.6844\u001b[0m            0.2666      415.0678  0.0010  576.5253\n",
      "     25            0.2647        \u001b[32m0.6832\u001b[0m            0.2620      475.3759  0.0007  576.6674\n",
      "     26            0.2847        \u001b[32m0.6669\u001b[0m            0.2739      444.9908  0.0005  583.2686\n",
      "     27            0.2867        0.6677            0.2778      403.6993  0.0003  580.1973\n",
      "     28            0.2843        \u001b[32m0.6576\u001b[0m            0.2685      399.6765  0.0001  580.5828\n",
      "     29            0.2836        \u001b[32m0.6566\u001b[0m            0.2662      392.9473  0.0000  501.2925\n",
      "     30            0.2836        \u001b[32m0.6553\u001b[0m            0.2662      392.9473  0.0000  327.5559\n"
     ]
    }
   ],
   "source": [
    "clf = EEGClassifier(\n",
    "    model,\n",
    "    cropped=True,\n",
    "    criterion=CroppedLoss,\n",
    "    criterion__loss_function=torch.nn.functional.nll_loss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    train_split=predefined_split(valid_set),\n",
    "    optimizer__lr=lr,\n",
    "    optimizer__weight_decay=weight_decay,\n",
    "    iterator_train__shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"accuracy\",\n",
    "        (\"lr_schedu6ler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    "    classes=classes,\n",
    ")\n",
    "# Model training for a specified number of epochs. `y` is None as it is already supplied\n",
    "# in the dataset.\n",
    "_ = clf.fit(train_set, y=None, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3d0d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03f1b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='Deep_clf_no_batch_norm.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50cc2a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Deep_clf_no_batch_norm.sav']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(clf,file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dea736a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegenv",
   "language": "python",
   "name": "eegenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
